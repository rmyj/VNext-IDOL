{"cells":[{"cell_type":"markdown","metadata":{"id":"cphx3dgyA9Bf"},"source":["<p align=\"center\"><img src=\"https://github.com/wjf5203/VNext/raw/main/assets/VNext.png\" width=\"300\"/></p>\n","\n","- VNext is a **Next**-generation **V**ideo instance recognition framework on top of [Detectron2](https://github.com/facebookresearch/detectron2). \n","- Currently it provides advanced online and offline video instance segmentation algorithms."]},{"cell_type":"markdown","metadata":{"id":"jLo8Y903BPH4"},"source":["## IDOL\n","\n","### Introduction\n","\n","- In recent years, video instance segmentation (VIS) has been largely advanced by offline models, while online models are usually inferior to the contemporaneous offline models by over 10 AP, which is a huge drawback.\n","\n","- By dissecting current online models and offline models, we demonstrate that the main cause of the performance gap is the error-prone association and  propose IDOL, which outperforms all online and offline methods on three benchmarks. \n","\n","- IDOL won first place in the video instance segmentation track of the 4th Large-scale Video Object Segmentation Challenge (CVPR2022)."]},{"cell_type":"markdown","metadata":{"id":"Cwijc4t44k9o"},"source":["# Installation\n","\n","***\n","\n","First, ensure the runtime type is set to GPU. Then clone the repository locally:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671757413667,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"o0QKzhTERbVj"},"outputs":[],"source":["!rm -r /content/*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5322,"status":"ok","timestamp":1671757418986,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"FCG4Y4ZK4Y80","outputId":"e412ec1e-8090-43f1-93ec-1975a121dd61"},"outputs":[],"source":["!git clone https://github.com/wjf5203/VNext.git\n","%cd VNext"]},{"cell_type":"markdown","metadata":{"id":"ouaODWAi4ow1"},"source":["Install dependencies and pycocotools for VIS:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":226584,"status":"ok","timestamp":1671757645567,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"alSXT1qV42gn","outputId":"ce961234-ed2b-4e7d-9b25-c10241066ed4"},"outputs":[],"source":["!pip install -r requirements.txt\n","!pip install -e .\n","!pip install shapely==1.7.1\n","!pip install git+https://github.com/youtubevos/cocoapi.git\\#\"egg=pycocotools&subdirectory=PythonAPI\" # not sure if this works"]},{"cell_type":"markdown","metadata":{"id":"xOKkZm9m47Ns"},"source":["Compiling Deformable DETR CUDA operators:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59270,"status":"ok","timestamp":1671757704831,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"62Zppiu_47po","outputId":"50a07e9f-bdb0-421f-e1ca-3606ead2e31c"},"outputs":[],"source":["%cd projects/IDOL/idol/models/ops/\n","!sh make.sh"]},{"cell_type":"markdown","metadata":{"id":"kBVdTdir4-dD"},"source":["# Data Preparation\n","\n","***\n","\n","Download and extract 2019 version of YoutubeVIS train and val images with annotations from CodeLab or YouTubeVIS, download OVIS and COCO 2017 datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43989,"status":"ok","timestamp":1671757748811,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"stf2wknK-wAS","outputId":"0cf0aba5-4ec7-44c6-86da-da0657619bde"},"outputs":[],"source":["# download validation set\n","\n","# designed for Google Colab\n","%cd /content/\n","for i in range(15):\n","  i = i + 1\n","  url = f\"https://github.com/rmyj/VNext-IDOL/-/raw/main/assets/valid.zip.{i:03}\"\n","  !wget $url # shows error but works \n","\n","# concatenate all part files to one zip\n","!cat /content/valid.zip* > /content/valid.zip\n","!rm /content/valid.zip.*\n","\n","# repair combination\n","!zip -FF /content/valid.zip --out /content/valid-full.zip\n","!rm /content/valid.zip\n","\n","# unzip combination\n","!apt-get install -y unzip\n","!unzip /content/valid-full.zip\n","!rm /content/valid-full.zip\n","\n","# to download cocopretrain_R50.pth - designed for Google Colab\n","%cd /content/\n","!wget https://github.com/rmyj/VNext-IDOL/-/raw/main/assets/cocopretrain_R50.zip\n","!unzip /content/cocopretrain_R50.zip\n","!rm /content/cocopretrain_R50.zip\n","\n","# create appropriate structure directory\n","!mkdir /content/VNext/datasets/ytvis_2021\n","!mkdir /content/VNext/datasets/ytvis_2021/annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1671757748812,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"Vt0lOd7oH-mL"},"outputs":[],"source":["!cp /content/valid/instances.json /content/VNext/datasets/ytvis_2021/annotations/instances_val_sub.json"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1671757748813,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"iEwV2Q0jIMgJ"},"outputs":[],"source":["!mv /content/valid /content/VNext/datasets/ytvis_2021/val"]},{"cell_type":"markdown","metadata":{"id":"BcecscFB7N4Q"},"source":["Extract YouTube-VIS 2019, OVIS, COCO 2017 datasets, we expect the directory structure to be the following:\n","\n","```\n","VNext\n","├── datasets\n","│   ├──ytvis_2019\n","│   ├──ovis \n","│   ├──coco \n","...\n","ytvis_2019\n","├── train\n","├── val\n","├── annotations\n","│   ├── instances_train_sub.json\n","│   ├── instances_val_sub.json\n","...\n","ovis\n","├── train\n","├── valid\n","├── annotations_train.json\n","├── annotations_valid.jso\n","...\n","coco\n","├── train2017\n","├── val2017\n","├── annotations\n","│   ├── instances_train2017.json\n","│   ├── instances_val2017.json\n","```"]},{"cell_type":"markdown","metadata":{"id":"ZOrlqquZ84nK"},"source":["# Inference & Evaluation\n","\n","***\n","\n","Evaluating on YouTube-VIS 2021:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3470,"status":"ok","timestamp":1671757752222,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"6ksfRG1JyvMu","outputId":"8d685708-6ab0-43b9-f300-b96c4132a64d"},"outputs":[],"source":["%cd /content/VNext\n","!python3 /content/VNext/projects/IDOL/train_net.py --help"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1328658,"status":"ok","timestamp":1671759080870,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"YSwFt1KQ-C88","outputId":"7ca3367e-2f20-4511-cf29-53ed2a04db82"},"outputs":[],"source":["%cd /content/VNext\n","!python3 /content/VNext/projects/IDOL/train_net.py --config-file /content/VNext/projects/IDOL/configs/ytvis21_r50.yaml --num-gpus 1 --eval-only MODEL.WEIGHTS /content/cocopretrain_R50.pth"]},{"cell_type":"markdown","metadata":{"id":"4cPM6BhmU3Se"},"source":["**WARNING: ** if you have a ModuleNotFoundError then make.sh failed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671759117273,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"i-1I1EpbSZUP","outputId":"b1f8691c-4187-4b12-e8f8-b628e46b74bb"},"outputs":[],"source":["%cd /content\n","!zip -r /content/IDOL_YTVIS21_R50.zip /content/VNext/IDOL_YTVIS21_R50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71735,"status":"ok","timestamp":1671759192371,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"XTSGYrcagrvn","outputId":"2d659626-ef50-4370-e88a-9cb9695b7589"},"outputs":[],"source":["!zip -r /content/VNext.zip /content/VNext"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":692,"status":"ok","timestamp":1671769861409,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"pzZ3-nRMgyRC","outputId":"e9c3d0ba-aa0f-449b-e33c-f4efa238c300"},"outputs":[],"source":["files.download('/content/VNext.zip')"]},{"cell_type":"markdown","metadata":{"id":"snGUzwq_h21q"},"source":["## Experimental"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4990,"status":"ok","timestamp":1671759087386,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"04wOipnxh4BI","outputId":"f707a264-074f-4b2b-d1ee-198067ddd753"},"outputs":[],"source":["%cd /content/VNext\n","!python3 /content/VNext/projects/IDOL/train_net.py --num-gpus 1 --eval-only MODEL.WEIGHTS /content/cocopretrain_R50.pth"]},{"cell_type":"markdown","metadata":{"id":"f4gZXUfrm_5Y"},"source":["the pipeline must have a config file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23797,"status":"ok","timestamp":1671766094520,"user":{"displayName":"Jeremy Shanks","userId":"09471794046381675701"},"user_tz":-780},"id":"AJTbF9o-medY","outputId":"919d27c5-03a8-4e7e-8e58-63501bef657f"},"outputs":[],"source":["# to download tokyostones.zip - designed for Google Colab\n","%cd /content/\n","!wget https://github.com/rmyj/VNext-IDOL/-/raw/main/assets/tokyostones.zip\n","!unzip /content/tokyostones.zip\n","!rm /content/tokyostones.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to download rgbd_dataset_freiburg3_walking_xyz_rgb_only - designed for Google Colab\n","%cd /content/\n","!wget https://github.com/rmyj/VNext-IDOL/-/raw/main/assets/rgbd_dataset_freiburg3_walking_xyz_rgb_only.zip\n","!unzip /content/rgbd_dataset_freiburg3_walking_xyz_rgb_only.zip\n","!rm /content/rgbd_dataset_freiburg3_walking_xyz_rgb_only.zip"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOS1VtlqlCND8/aZGiTiMDa","mount_file_id":"103WGDjqgBvXIH4FAiVZX7pfj5eM6Kpnl","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"cdf433682cbe9968d7764873f87164db8641effb758ebee62e489150bdf64f5a"}}},"nbformat":4,"nbformat_minor":0}
